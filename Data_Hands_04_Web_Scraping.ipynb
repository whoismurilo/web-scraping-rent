{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Hands #04 - Web Scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKkix1LDAfUl"
      },
      "source": [
        "<p align=\"center\"><img src=\"https://lp.eloscience.com/wp-content/uploads/2021/01/data-hands.png\" width=\"60%\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_cjbtue9RkY"
      },
      "source": [
        "The housing market is something that everyone living in any country has to deal with and, as a result, is a great topic about data analysis.<br>\n",
        "<br>\n",
        "Within the next few days I will be moving to another city and I took the opportunity to use python to be able to research some houses and identify potential opportunities in that market.<br>\n",
        "<br>\n",
        "I will use Web Scraping to extract data from the real estate market.<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiEwKroj8zjo"
      },
      "source": [
        "# **Part I - Understanding how Web Scraping works**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaD0Cvc_LgNQ"
      },
      "source": [
        "## **1. Importing the libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJVD6Kv8_iOo"
      },
      "source": [
        "In this first phase, we will only need these 3 libraries, **`requests`** will request our web page, **`pandas`** will create our dataframe at the end with the data obtained. And we also have **`bs4`**, more precisely `BeautifulSoup`, this will be responsible for obtaining the `tags` of our HTML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXg9ocb5h-5h"
      },
      "source": [
        "# create iterators\n",
        "import itertools \n",
        "\n",
        "# create dataframe and analyze data\n",
        "import pandas       as pd\n",
        "\n",
        "# inspect html\n",
        "from bs4            import BeautifulSoup\n",
        "\n",
        "# make requests to the site\n",
        "from requests       import get\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g1ecZv0Elpx"
      },
      "source": [
        "We are going to create headers, as many sites block any type of scraping. The header will be created using the `User-Agent`, in it we will pass each type of different browser and their respective versions. Here we don't have to worry about how it works, the model is standard and we will simply replicate that pattern within our variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz7l1A3DiPyk"
      },
      "source": [
        "headers = ({'User-Agent':\n",
        "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hUwFFJUIfM9"
      },
      "source": [
        "## **2. Fazer a requisição do site**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W9685lqIqba"
      },
      "source": [
        "A primeira coisa que precisamos fazer é criar uma variável, essa variável vai receber o endereço do nosso site de pesquisa. Após isso, precisamos fazer a requisição utilizando a biblioteca `requests` e passando o headers que criamos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNJPn1POiaj3"
      },
      "source": [
        "sapo = 'https://casa.sapo.pt/alugar-apartamentos/odivelas/'\n",
        "response = get(sapo, headers=headers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjiaGdxXJ8aK"
      },
      "source": [
        "Here we simply visualize the response to our request, by default the results that start with 2 indicate success."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt2FQbyyisC5",
        "outputId": "525fca98-6ca3-41a0-ce29-971e425c472d"
      },
      "source": [
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LscERkV4K8GU"
      },
      "source": [
        "## **3. HTML analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkN1wnK_LIRe"
      },
      "source": [
        "We will use the BeatifulSoup library, in it we will pass our request and transform it into text using **`.text`**. In this step, we also need to pass another parameter called **'parser'**. We have a few options available, but in this example we will use the parameter **'lxml'**, as it is light and faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RFip-zit1Y"
      },
      "source": [
        "soup = BeautifulSoup(response.text, 'lxml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD8ts_U5Oq8l"
      },
      "source": [
        "After inspecting our HTML content, we were able to view the information we wanted. We need to identify which tag we are going to use to extract the data, in our example we identified the tag **`div` ** containing the content we are going to use. After identifying the tag, we also need to obtain the class of our tag. The class will more objectively identify our content.\n",
        "<br>\n",
        "<br>\n",
        "We pass all this inside the function **`.find_all`**, this function as the name says, will find all the information according to the parameters that we put, in our example it is the tag **`div`** and the **`class`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QneUpUUrkHxS"
      },
      "source": [
        "house_containers = soup.find_all('div', class_='searchResultProperty item hastitle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fieAyrT8UHir"
      },
      "source": [
        "We need to create a variable that will store our content extracted from the tag, and soon after, you will notice that we use the function **`.find_all`**, but searching within our content already extracted the tag **`span`** ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mYBgYpZlGpx",
        "outputId": "78a8d311-de1f-41ed-b81d-216ee871e357"
      },
      "source": [
        "first = house_conteiners[0]\n",
        "first.find_all('span')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<span class=\"titleG3\">T2 em Odivelas recuperado junto ao Mcdonald`s</span>,\n",
              " <span class=\"messengerOFFLINE\" id=\"MC_PropertyInList_repProperties_spanMessenger_1\" onclick=\"goToMessenger('/a30df3c4-5d76-11eb-921c-060000000052.html');\" style=\"cursor: pointer;\">\n",
              " <i class=\"fa fa-comment fa-lg\"></i>\n",
              " </span>,\n",
              " <span>\n",
              "                         Apartamento T2, Odivelas, Lisboa\n",
              "                     </span>,\n",
              " <span class=\"btnContactPVPI\" id=\"MC_PropertyInList_repProperties_btnContactPVPINormal_1\" onclick=\"ShowContactForm('a30df3c4-5d76-11eb-921c-060000000052', '4', '5', true, false, '0'); return false;\" style=\"z-index: 9999;\" title=\"Contacte Anunciante\">Contacte Anunciante</span>,\n",
              " <span>800 <strong title=\"Euro\">€</strong></span>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZAXuXFHwH0_"
      },
      "source": [
        "### **3.1 Getting the Price**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVnaDQwhp5Ks"
      },
      "source": [
        "When doing this, we then receive an element containing only what we request. Now the next step is to obtain the property prices separately and using the same pattern used in the previous steps, calling the tag **`span`**, then passing its location on the list and finally, converting it to text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qZpJ_HMoli_y",
        "outputId": "71ba3e65-7a50-43c6-81ab-af9955e72d04"
      },
      "source": [
        "price_1 = first.find_all('span')[-1].text\n",
        "price_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'800 €'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp0-Ii7lvKV0"
      },
      "source": [
        "**3.1.2 If necessary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXBmFYg5sYnE"
      },
      "source": [
        "We can see at this point that when requesting this information, the correct value was returned, but containing the following signaling **'1 \\ xa0'**. We will then need to do a **`.replace()`** in order to replace this unsolicited value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fl8SXGues_kY",
        "outputId": "6ee5bdc9-97ea-493b-9f56-a2af26b106d7"
      },
      "source": [
        "price_1 = price_1.replace('1\\xa0', '')\n",
        "price_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'800 €'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lvbLttpxXkI"
      },
      "source": [
        "You will need to transform this data using the iterator. In it we will join the empty spaces that we replaced using the function **.Join()** and using the function **.Takewhile()** we will take this value and transform it into a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9bDbPw_t-V1",
        "outputId": "eb275b7b-5e48-4419-8d79-c82469c2864b"
      },
      "source": [
        "price_1 = int(''.join(itertools.takewhile(str.isdigit, price_1)))\n",
        "print(price_1, type(price_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800 <class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21ZkwwRSwecy"
      },
      "source": [
        "### **3.2 Location**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKY2JYtUwsJ9"
      },
      "source": [
        "Here the process is very similar to the previous one, the only difference is that we need to find the tag that indicates the location of the properties and we will also need the name of the class to which it belongs. In our example, the tag containing this information is a paragraph tag ie **`p`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2GdnK0O_mVP1",
        "outputId": "5f99be39-42d8-4781-b3e2-749d9f0cb26d"
      },
      "source": [
        "location = first.find_all('p', class_='searchPropertyLocation HasFeatures')[0].text\n",
        "location"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\r\\n                    Odivelas, Lisboa\\r\\n                '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uErba0BOyxXB"
      },
      "source": [
        "Again when extracting empty spaces and unwanted letters came, but this is easily solved using the pandas function called **`.strip()`**. However, we need to define which word we are going to extract, as we know the city very well and we only want the name of the neighborhoods, we can simply delimit our extraction by placing the limit \"**,(vírgula)**\" as a limit. So, every time my scraping is performed and finds our delimiter, it will simply stop and show just what we asked for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1eS1MKj-ng5X",
        "outputId": "5b5a8ab7-4a04-4970-e094-9f9749e58c24"
      },
      "source": [
        "location[7:location.find(',')].strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Odivelas'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05qJloy40oZS"
      },
      "source": [
        "### **3.3 Size of the Property**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvDwpr5J0xr2"
      },
      "source": [
        "This is the simplest part of our job, here we will only request the tag **`p`** and pass the position of our property sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i0mCLuOn5ZI",
        "outputId": "f18e69c0-e497-4fae-bb0d-f5a0cfd62e33"
      },
      "source": [
        "first.find_all('p')[7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<p>100m²</p>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWXYAHWS3M0W"
      },
      "source": [
        "### **3.4 Property Description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Udw_i64Wll"
      },
      "source": [
        "We use the pattern we are used to, which consists of: searching for the tag, getting the class, converting it to text and applying the strip to eliminate the empty spaces in our text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JeFhoqYSo1b_",
        "outputId": "a62dea7d-1804-43ae-f12e-cfcad62aecb0"
      },
      "source": [
        "first.find_all('p', class_='searchPropertyDescription')[0].text.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T2 recuperado junto ao Mcdonald`s e escola secundária de Odivelas, com áreas bastante generosas situado num prédio em bom estado de conservação, composto por, cozinha semi-equipada, dispensa, quarto com janelas duplas, casa (...)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1M3wVoW4_WL"
      },
      "source": [
        "### **3.5 Extract links**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR3zm4Ur5F_v"
      },
      "source": [
        "Now we want to extract the links to be able to consult more simply and quickly. For this, we will use a **`loop for`**, which will inspect our HTML and take only the link tag that is **`a`**. That done, let's make the request by calling the link reference **`href`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KviKT1a_ptj8",
        "outputId": "1dffd3da-9f33-4f43-a969-42b90c866a10"
      },
      "source": [
        "for url in first.find_all('a'):\n",
        "  print(url.get('href'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/alugar-apartamento-t2-odivelas-perto-escola,centro-da-cidade,policia,transportes-publicos-com-arrecadacao-tem-varandas,sotao,marquise,varanda-a30df3c4-5d76-11eb-921c-060000000052.html\n",
            "/alugar-apartamento-t2-odivelas-perto-escola,centro-da-cidade,policia,transportes-publicos-com-arrecadacao-tem-varandas,sotao,marquise,varanda-a30df3c4-5d76-11eb-921c-060000000052.html\n",
            "/agencia/h4-mediacao-imobiliaria,-lda/?cl=14135&sys=5\n",
            "/alugar-apartamento-t2-odivelas-perto-escola,centro-da-cidade,policia,transportes-publicos-com-arrecadacao-tem-varandas,sotao,marquise,varanda-a30df3c4-5d76-11eb-921c-060000000052.html\n",
            "/alugar-apartamento-t2-odivelas-perto-escola,centro-da-cidade,policia,transportes-publicos-com-arrecadacao-tem-varandas,sotao,marquise,varanda-a30df3c4-5d76-11eb-921c-060000000052.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKQZWFxc7F5a"
      },
      "source": [
        "And to top it off, we can create a concatenation by joining the default website address with the complement of the website that comes after **`/`**. The only attention we must take is to slice the link, because if it is not done the browser will not recognize the link we created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hFIQNRehryau",
        "outputId": "e74acb13-939d-4c45-beeb-6e0a0656c232"
      },
      "source": [
        "'https//casa.sapo.pt/' + first.find_all('a')[0].get('href')[1:-5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https//casa.sapo.pt/alugar-apartamento-t2-odivelas-perto-escola,centro-da-cidade,policia,transportes-publicos-com-arrecadacao-tem-varandas,sotao,marquise,varanda-a30df3c4-5d76-11eb-921c-060000000052'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUwl7l62-qeE"
      },
      "source": [
        "# **Part II - Store the data in a DataFrame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7awKQGpf_212"
      },
      "source": [
        "In this step we will gather everything you have learned and create a DataFrame so that we can store our data in a simple and clear way. First, we will need to create an empty list for each topic we are going to extract, that list will be filled with our data in a more organized way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrOQlo4ZCLzV"
      },
      "source": [
        "## **4.0 Empty lists**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIP29jxitl0x"
      },
      "source": [
        "titles = []\n",
        "prices = []\n",
        "areas = []\n",
        "zone = []\n",
        "condition = []\n",
        "descriptions = []\n",
        "urls = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnhc6pmvCDqP"
      },
      "source": [
        "## **4.1 Loop to extract data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNGuffs2Fk27"
      },
      "source": [
        "Moving towards the end of our project, we will need to create the for loop to be able to capture the data we want. For this, we will just repeat the processes previously done with the difference that will be inside the loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCuEh2lTt62e",
        "outputId": "38734f19-7c62-4914-97c4-bfa390c8c60b"
      },
      "source": [
        "%%time\n",
        "\n",
        "n_pages = 0\n",
        "\n",
        "for page in range(0,10):\n",
        "    n_pages += 1\n",
        "    sapo_url = 'https://casa.sapo.pt/alugar-apartamentos/odivelas/'+'&pn='+str(page)\n",
        "    r = get(sapo_url, headers=headers)\n",
        "    page_html = BeautifulSoup(r.text, 'lxml')\n",
        "    house_conteiners = soup.find_all('div', class_='searchResultProperty item hastitle')\n",
        "    if house_containers != []:\n",
        "        for container in house_containers:\n",
        "            \n",
        "            # Price            \n",
        "            price = container.find_all('span')[2].text\n",
        "            if price == 'Contacte Anunciante':\n",
        "                price = container.find_all('span')[3].text\n",
        "                if price.find('/') != -1:\n",
        "                    price = price[0:price.find('/')-1]\n",
        "            if price.find('/') != -1:\n",
        "                price = price[0:price.find('/')-1]\n",
        "            \n",
        "            price_ = [int(price[s]) for s in range(0,len(price)) if price[s].isdigit()]\n",
        "            price = ''\n",
        "            for x in price_:\n",
        "                price = price+str(x)\n",
        "            prices.append(int(price))\n",
        "\n",
        "            # Zone\n",
        "            location = container.find_all('p', class_='searchPropertyLocation HasFeatures')[0].text\n",
        "            location = location[7:location.find(',')]\n",
        "            zone.append(location)\n",
        "\n",
        "            # Title\n",
        "            name = container.find_all('span')[0].text\n",
        "            titles.append(name)\n",
        "\n",
        "            # Status\n",
        "            status = container.find_all('p')[5].text\n",
        "            condition.append(status)\n",
        "\n",
        "            # Area\n",
        "            m2 = container.find_all('p')[9].text\n",
        "            if m2 != '-':\n",
        "                m2 = m2.replace('\\xa0','')\n",
        "                m2 = float(\"\".join(itertools.takewhile(str.isdigit, m2)))\n",
        "                areas.append(m2)\n",
        "                \n",
        "            else:\n",
        "                m2 = container.find_all('p')[7].text\n",
        "                if m2 != '-':\n",
        "                    m2 = m2.replace('\\xa0','')\n",
        "                    m2 = float(\"\".join(itertools.takewhile(str.isdigit, m2)))\n",
        "                    areas.append(m2)\n",
        "                else:\n",
        "                    areas.append(m2)\n",
        "\n",
        "            # Description\n",
        "            desc = container.find_all('p', class_='searchPropertyDescription')[0].text[:-1].strip()\n",
        "            descriptions.append(desc)\n",
        "\n",
        "            # url\n",
        "            link = 'https://casa.sapo.pt/' + container.find_all('a')[0].get('href')[1:-5]\n",
        "            urls.append(link)\n",
        "\n",
        "    else:\n",
        "        break\n",
        "    \n",
        "print('You scraped {} pages containing {} properties.'.format(n_pages, len(titles)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You scraped 10 pages containing 180 properties.\n",
            "CPU times: user 573 ms, sys: 13 ms, total: 586 ms\n",
            "Wall time: 8.77 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbspHdQVJ3f0"
      },
      "source": [
        "## **4.2 DataFrame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbpV-roKMfA5"
      },
      "source": [
        "## **4.2.1 - Creating the DataFrame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1-sJJUrJ_9f"
      },
      "source": [
        "Here we are going to create a list containing the column names. After doing this process, we will create a variable with the name of the location I chose. Within this variable, we will use the **`.DataFrame`** function and here we will use a dictionary using our column headings and placing our data stored within the headings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qube_Gm8hkM"
      },
      "source": [
        "cols = ['Title', 'Zone', 'Price', 'Size (m²)', 'Status', 'Description', 'URL']\n",
        "\n",
        "odivelas = pd.DataFrame({'Title': titles,\n",
        "                           'Price': prices,\n",
        "                           'Size (m²)': areas,\n",
        "                           'Zone': zone,\n",
        "                           'Status': condition,\n",
        "                           'Description': descriptions,\n",
        "                           'URL': urls})[cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRTh3w3BLF4O"
      },
      "source": [
        "### **4.2.2 Confirming the DataFrame creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "JydujsnEJ2eB",
        "outputId": "fba97418-7bd9-43c6-c6c3-ad0882179e9e"
      },
      "source": [
        "odivelas.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Zone</th>\n",
              "      <th>Price</th>\n",
              "      <th>Size (m²)</th>\n",
              "      <th>Status</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apartamento T2 com Parqueamentos e Arrecadação...</td>\n",
              "      <td>Colinas do Cruzeiro</td>\n",
              "      <td>1250</td>\n",
              "      <td>101.0</td>\n",
              "      <td>Usado</td>\n",
              "      <td>APARTAMENTO T2 com Parqueamentos e Arrecadação...</td>\n",
              "      <td>https://casa.sapo.pt/alugar-apartamento-t2-odi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T2 - Centro Casal de Cambra</td>\n",
              "      <td>Caneças</td>\n",
              "      <td>2</td>\n",
              "      <td>90.0</td>\n",
              "      <td>Usado</td>\n",
              "      <td>T2 C/ Arrecadação Centro de Casal de Cambra Ex...</td>\n",
              "      <td>https://casa.sapo.pt/alugar-apartamento-t2-odi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apartamento T2 na Urb. do Jardim da Amoreira</td>\n",
              "      <td>Jardim da Amoreira  (Ramada)</td>\n",
              "      <td>2</td>\n",
              "      <td>103.0</td>\n",
              "      <td>Usado</td>\n",
              "      <td>|| Em Exclusivo na PMC Imobiliária || Numa das...</td>\n",
              "      <td>https://casa.sapo.pt/alugar-apartamento-t2-odi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T2+1 -- Excelentes Condições -- Caneças</td>\n",
              "      <td>Caneças</td>\n",
              "      <td>3</td>\n",
              "      <td>95.0</td>\n",
              "      <td>Usado</td>\n",
              "      <td>Sala c/ 30m2, Cozinha em Kitchenette  Cozinha ...</td>\n",
              "      <td>https://casa.sapo.pt/alugar-apartamento-t3-odi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Apartamento T2 em Odivelas c/ cozinha equipada</td>\n",
              "      <td>Póvoa de Santo Adrião e Olival ...</td>\n",
              "      <td>2</td>\n",
              "      <td>80.0</td>\n",
              "      <td>Usado</td>\n",
              "      <td>FAÇA CONNOSCO O MELHOR NEGÓCIO   Excelente Opo...</td>\n",
              "      <td>https://casa.sapo.pt/alugar-apartamento-t2-odi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                                URL\n",
              "0  Apartamento T2 com Parqueamentos e Arrecadação...  ...  https://casa.sapo.pt/alugar-apartamento-t2-odi...\n",
              "1                        T2 - Centro Casal de Cambra  ...  https://casa.sapo.pt/alugar-apartamento-t2-odi...\n",
              "2       Apartamento T2 na Urb. do Jardim da Amoreira  ...  https://casa.sapo.pt/alugar-apartamento-t2-odi...\n",
              "3            T2+1 -- Excelentes Condições -- Caneças  ...  https://casa.sapo.pt/alugar-apartamento-t3-odi...\n",
              "4     Apartamento T2 em Odivelas c/ cozinha equipada  ...  https://casa.sapo.pt/alugar-apartamento-t2-odi...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4WGIPvVLWQu",
        "outputId": "2e44f15d-7a7b-4a99-f3ac-99a3c2e631a0"
      },
      "source": [
        "odivelas.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpVQV-zQLdXC",
        "outputId": "ed2110a1-dc5a-4f64-dbea-946c102b7c73"
      },
      "source": [
        "odivelas.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 180 entries, 0 to 179\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Title        180 non-null    object \n",
            " 1   Zone         180 non-null    object \n",
            " 2   Price        180 non-null    int64  \n",
            " 3   Size (m²)    180 non-null    float64\n",
            " 4   Status       180 non-null    object \n",
            " 5   Description  180 non-null    object \n",
            " 6   URL          180 non-null    object \n",
            "dtypes: float64(1), int64(1), object(5)\n",
            "memory usage: 10.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Lf9a8kJKLgFV",
        "outputId": "69d84921-45ad-49e0-ae7d-cef31ca17082"
      },
      "source": [
        "odivelas.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Size (m²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>180.000000</td>\n",
              "      <td>180.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9173.333333</td>\n",
              "      <td>90.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>36685.537683</td>\n",
              "      <td>26.450767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>93.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>750.000000</td>\n",
              "      <td>103.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>160000.000000</td>\n",
              "      <td>125.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Price   Size (m²)\n",
              "count     180.000000  180.000000\n",
              "mean     9173.333333   90.722222\n",
              "std     36685.537683   26.450767\n",
              "min         2.000000   14.000000\n",
              "25%         2.000000   84.000000\n",
              "50%         3.000000   93.500000\n",
              "75%       750.000000  103.000000\n",
              "max    160000.000000  125.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1NMrFzZMGCF"
      },
      "source": [
        "### **4.2.3 Exporting the DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSydyIMDLph1"
      },
      "source": [
        "# EXCEL\n",
        "odivelas.to_excel('odivelas_excel.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um1FcvGSNCr-"
      },
      "source": [
        "# DATAFRAME\n",
        "odivelas.to_csv('odivelas_csv.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jKtW9LoNJBt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}